{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import  Transformer,Estimator\n",
    "from pyspark.ml.param.shared import HasInputCol,HasOutputCol,HasInputCols,HasOutputCols\n",
    "from pyspark import keyword_only\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import *\n",
    "\n",
    "class LabelEncode(Transformer,HasInputCol,HasOutputCol,HasInputCols,HasOutputCols):\n",
    "    @keyword_only\n",
    "    def __init__(self,outputCols=None):\n",
    "        super(LabelEncode,self).__init__()\n",
    "        kwargs=self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "    @keyword_only\n",
    "    def setParams(self,inputCol=None,outputCols=None):\n",
    "        kwargs=self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    #def xv(self):\n",
    "        #print('xv')\n",
    "    def _transform(self,df):\n",
    "        label_col=self.getOutputCols()\n",
    "        independent_df=df.select(*list(set(df.columns)-set(label_col)))\n",
    "        from pyspark.ml.feature import VectorAssembler,OneHotEncoder,StringIndexer\n",
    "        cc=[cat[0] for cat in independent_df.dtypes if cat[1]=='string']\n",
    "        for column in cc:\n",
    "            sti=StringIndexer(inputCol=column,outputCol='index_'+column)\n",
    "            df=sti.fit(df).transform(df)\n",
    "            df=df.drop(column)\n",
    "        return df\n",
    "    \n",
    "class OHEncode(Transformer,HasInputCol,HasOutputCol,HasOutputCols):\n",
    "    @keyword_only\n",
    "    def __init__(self):\n",
    "        super(OHEncode,self).__init__()\n",
    "        kwargs=self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "    @keyword_only\n",
    "    def setParams(self,inputCol=None,outputCol=None):\n",
    "        kwargs=self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    #def xv(self):\n",
    "        #print('xv')\n",
    "    def _transform(self,df):\n",
    "        from pyspark.ml.feature import VectorAssembler,OneHotEncoder,StringIndexer\n",
    "        #label_column=df.select('TARGET')\n",
    "        #df=df.drop('TARGET')\n",
    "        ohe_columns=[col for col in df.columns if col.startswith('index_')]\n",
    "        ohe_columns=[col for col in ohe_columns if df.select(col).distinct().count()]\n",
    "        for column in ohe_columns:\n",
    "            sti=OneHotEncoder(inputCol=column,outputCol='ohe_'+column)\n",
    "            df=sti.transform(df)\n",
    "            df=df.drop(column)\n",
    "        #print(df.columns)\n",
    "        #df=df.join(label_column)\n",
    "        return df\n",
    "    \n",
    "class VectorChange(Transformer,HasInputCol,HasOutputCol,HasOutputCols):\n",
    "    @keyword_only\n",
    "    def __init__(self,outputCols=None):\n",
    "        super(VectorChange,self).__init__()\n",
    "        kwargs=self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "        \n",
    "    @keyword_only\n",
    "    def setParams(self,inputCol=None,outputCols=None):\n",
    "        kwargs=self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    #def xv(self):\n",
    "        #print('xv')\n",
    "    def _transform(self,df):\n",
    "        \n",
    "        target_col=self.getOutputCols()\n",
    "        from pyspark.ml.feature import VectorAssembler,OneHotEncoder,StringIndexer\n",
    "        #print(list(set(df.columns)-set(target_col)))\n",
    "        assem=VectorAssembler(inputCols=list(set(df.columns)-set(target_col)),outputCol='Feature')\n",
    "        df=assem.transform(df)\n",
    "        #print(df.select('Feature').show())\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('product').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=spark.read.parquet('cleaned_file_v1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data1.limit(700000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[ncodpers: double, ind_empleado: string, pais_residencia: string, sexo: string, age: string, ind_nuevo: string, antiguedad: string, indrel: string, indrel_1mes: string, tiprel_1mes: string, indresi: string, indext: string, canal_entrada: string, indfall: string, tipodom: string, cod_prov: string, nomprov: string, ind_actividad_cliente: string, segmento: string, ind_ahor_fin_ult1: int, ind_aval_fin_ult1: int, ind_cco_fin_ult1: int, ind_cder_fin_ult1: int, ind_cno_fin_ult1: int, ind_ctju_fin_ult1: int, ind_ctma_fin_ult1: int, ind_ctop_fin_ult1: int, ind_ctpp_fin_ult1: int, ind_deco_fin_ult1: int, ind_deme_fin_ult1: int, ind_dela_fin_ult1: int, ind_ecue_fin_ult1: int, ind_fond_fin_ult1: int, ind_hip_fin_ult1: int, ind_plan_fin_ult1: int, ind_pres_fin_ult1: int, ind_reca_fin_ult1: int, ind_tjcr_fin_ult1: int, ind_valo_fin_ult1: int, ind_viv_fin_ult1: int, ind_nomina_ult1: string, ind_nom_pens_ult1: string, ind_recibo_ult1: int, imputed_renta: double]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisList=[col for col in data.columns if col.startswith('ind_') and col.endswith('ult1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(*['age','ind_nuevo','antiguedad','indrel','indrel_1mes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(*['ind_nomina_ult1','ind_nom_pens_ult1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncode(outputCols=thisList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = le.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[ncodpers: double, ind_ahor_fin_ult1: int, ind_aval_fin_ult1: int, ind_cco_fin_ult1: int, ind_cder_fin_ult1: int, ind_cno_fin_ult1: int, ind_ctju_fin_ult1: int, ind_ctma_fin_ult1: int, ind_ctop_fin_ult1: int, ind_ctpp_fin_ult1: int, ind_deco_fin_ult1: int, ind_deme_fin_ult1: int, ind_dela_fin_ult1: int, ind_ecue_fin_ult1: int, ind_fond_fin_ult1: int, ind_hip_fin_ult1: int, ind_plan_fin_ult1: int, ind_pres_fin_ult1: int, ind_reca_fin_ult1: int, ind_tjcr_fin_ult1: int, ind_valo_fin_ult1: int, ind_viv_fin_ult1: int, ind_recibo_ult1: int, imputed_renta: double, index_canal_entrada: double, index_indresi: double, index_indfall: double, index_ind_actividad_cliente: double, index_tipodom: double, index_cod_prov: double, index_segmento: double, index_sexo: double, index_nomprov: double, index_pais_residencia: double, index_ind_empleado: double, index_indext: double, index_tiprel_1mes: double]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OHEncode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=ohe.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[ncodpers: double, ind_ahor_fin_ult1: int, ind_aval_fin_ult1: int, ind_cco_fin_ult1: int, ind_cder_fin_ult1: int, ind_cno_fin_ult1: int, ind_ctju_fin_ult1: int, ind_ctma_fin_ult1: int, ind_ctop_fin_ult1: int, ind_ctpp_fin_ult1: int, ind_deco_fin_ult1: int, ind_deme_fin_ult1: int, ind_dela_fin_ult1: int, ind_ecue_fin_ult1: int, ind_fond_fin_ult1: int, ind_hip_fin_ult1: int, ind_plan_fin_ult1: int, ind_pres_fin_ult1: int, ind_reca_fin_ult1: int, ind_tjcr_fin_ult1: int, ind_valo_fin_ult1: int, ind_viv_fin_ult1: int, ind_recibo_ult1: int, imputed_renta: double, ohe_index_canal_entrada: vector, ohe_index_indresi: vector, ohe_index_indfall: vector, ohe_index_ind_actividad_cliente: vector, ohe_index_tipodom: vector, ohe_index_cod_prov: vector, ohe_index_segmento: vector, ohe_index_sexo: vector, ohe_index_nomprov: vector, ohe_index_pais_residencia: vector, ohe_index_ind_empleado: vector, ohe_index_indext: vector, ohe_index_tiprel_1mes: vector]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler,OneHotEncoder,StringIndexer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler=VectorAssembler(inputCols=list(set(data.columns)-set(thisList)),outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ncodpers: double (nullable = true)\n",
      " |-- ind_ahor_fin_ult1: integer (nullable = true)\n",
      " |-- ind_aval_fin_ult1: integer (nullable = true)\n",
      " |-- ind_cco_fin_ult1: integer (nullable = true)\n",
      " |-- ind_cder_fin_ult1: integer (nullable = true)\n",
      " |-- ind_cno_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ctju_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ctma_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ctop_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ctpp_fin_ult1: integer (nullable = true)\n",
      " |-- ind_deco_fin_ult1: integer (nullable = true)\n",
      " |-- ind_deme_fin_ult1: integer (nullable = true)\n",
      " |-- ind_dela_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ecue_fin_ult1: integer (nullable = true)\n",
      " |-- ind_fond_fin_ult1: integer (nullable = true)\n",
      " |-- ind_hip_fin_ult1: integer (nullable = true)\n",
      " |-- ind_plan_fin_ult1: integer (nullable = true)\n",
      " |-- ind_pres_fin_ult1: integer (nullable = true)\n",
      " |-- ind_reca_fin_ult1: integer (nullable = true)\n",
      " |-- ind_tjcr_fin_ult1: integer (nullable = true)\n",
      " |-- ind_valo_fin_ult1: integer (nullable = true)\n",
      " |-- ind_viv_fin_ult1: integer (nullable = true)\n",
      " |-- ind_recibo_ult1: integer (nullable = true)\n",
      " |-- imputed_renta: double (nullable = true)\n",
      " |-- ohe_index_canal_entrada: vector (nullable = true)\n",
      " |-- ohe_index_indresi: vector (nullable = true)\n",
      " |-- ohe_index_indfall: vector (nullable = true)\n",
      " |-- ohe_index_ind_actividad_cliente: vector (nullable = true)\n",
      " |-- ohe_index_tipodom: vector (nullable = true)\n",
      " |-- ohe_index_cod_prov: vector (nullable = true)\n",
      " |-- ohe_index_segmento: vector (nullable = true)\n",
      " |-- ohe_index_sexo: vector (nullable = true)\n",
      " |-- ohe_index_nomprov: vector (nullable = true)\n",
      " |-- ohe_index_pais_residencia: vector (nullable = true)\n",
      " |-- ohe_index_ind_empleado: vector (nullable = true)\n",
      " |-- ohe_index_indext: vector (nullable = true)\n",
      " |-- ohe_index_tiprel_1mes: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "model_preds = {}\n",
    "id_preds1 = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra=train.limit(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind_ahor_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.1964087583548715\n",
      "------------------------------------------------------------------------\n",
      "ind_aval_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.8205403549596558\n",
      "------------------------------------------------------------------------\n",
      "ind_cco_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.6683549162657136\n",
      "------------------------------------------------------------------------\n",
      "ind_cder_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.705103734891928\n",
      "------------------------------------------------------------------------\n",
      "ind_cno_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.6751380726718121\n",
      "------------------------------------------------------------------------\n",
      "ind_ctju_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.5\n",
      "------------------------------------------------------------------------\n",
      "ind_ctma_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.7092633071912446\n",
      "------------------------------------------------------------------------\n",
      "ind_ctop_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.1693379610861845\n",
      "------------------------------------------------------------------------\n",
      "ind_ctpp_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.6947800664335911\n",
      "------------------------------------------------------------------------\n",
      "ind_deco_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.6366453410287847\n",
      "------------------------------------------------------------------------\n",
      "ind_deme_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.7020617253714047\n",
      "------------------------------------------------------------------------\n",
      "ind_dela_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.6086343071638093\n",
      "------------------------------------------------------------------------\n",
      "ind_ecue_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.5409716630694414\n",
      "------------------------------------------------------------------------\n",
      "ind_fond_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.8648511504817569\n",
      "------------------------------------------------------------------------\n",
      "ind_hip_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.8191233741432983\n",
      "------------------------------------------------------------------------\n",
      "ind_plan_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.8267619012664493\n",
      "------------------------------------------------------------------------\n",
      "ind_pres_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.6386361000080951\n",
      "------------------------------------------------------------------------\n",
      "ind_reca_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.742935245714459\n",
      "------------------------------------------------------------------------\n",
      "ind_tjcr_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.7843935421534153\n",
      "------------------------------------------------------------------------\n",
      "ind_valo_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.3904461306170595\n",
      "------------------------------------------------------------------------\n",
      "ind_viv_fin_ult1\n",
      "...fitting\n",
      "fitted\n",
      "transformed\n",
      "0.7877023392066723\n",
      "------------------------------------------------------------------------\n",
      "ind_nomina_ult1\n",
      "...fitting\n"
     ]
    },
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Field \"ind_nomina_ult1\" does not exist.\\nAvailable fields: ncodpers, ind_ahor_fin_ult1, ind_aval_fin_ult1, ind_cco_fin_ult1, ind_cder_fin_ult1, ind_cno_fin_ult1, ind_ctju_fin_ult1, ind_ctma_fin_ult1, ind_ctop_fin_ult1, ind_ctpp_fin_ult1, ind_deco_fin_ult1, ind_deme_fin_ult1, ind_dela_fin_ult1, ind_ecue_fin_ult1, ind_fond_fin_ult1, ind_hip_fin_ult1, ind_plan_fin_ult1, ind_pres_fin_ult1, ind_reca_fin_ult1, ind_tjcr_fin_ult1, ind_valo_fin_ult1, ind_viv_fin_ult1, ind_recibo_ult1, imputed_renta, ohe_index_canal_entrada, ohe_index_indresi, ohe_index_indfall, ohe_index_ind_actividad_cliente, ohe_index_tipodom, ohe_index_cod_prov, ohe_index_segmento, ohe_index_sexo, ohe_index_nomprov, ohe_index_pais_residencia, ohe_index_ind_empleado, ohe_index_indext, ohe_index_tiprel_1mes, features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o3453.fit.\n: java.lang.IllegalArgumentException: Field \"ind_nomina_ult1\" does not exist.\nAvailable fields: ncodpers, ind_ahor_fin_ult1, ind_aval_fin_ult1, ind_cco_fin_ult1, ind_cder_fin_ult1, ind_cno_fin_ult1, ind_ctju_fin_ult1, ind_ctma_fin_ult1, ind_ctop_fin_ult1, ind_ctpp_fin_ult1, ind_deco_fin_ult1, ind_deme_fin_ult1, ind_dela_fin_ult1, ind_ecue_fin_ult1, ind_fond_fin_ult1, ind_hip_fin_ult1, ind_plan_fin_ult1, ind_pres_fin_ult1, ind_reca_fin_ult1, ind_tjcr_fin_ult1, ind_valo_fin_ult1, ind_viv_fin_ult1, ind_recibo_ult1, imputed_renta, ohe_index_canal_entrada, ohe_index_indresi, ohe_index_indfall, ohe_index_ind_actividad_cliente, ohe_index_tipodom, ohe_index_cod_prov, ohe_index_segmento, ohe_index_sexo, ohe_index_nomprov, ohe_index_pais_residencia, ohe_index_ind_empleado, ohe_index_indext, ohe_index_tiprel_1mes, features\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:274)\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:274)\n\tat scala.collection.MapLike$class.getOrElse(MapLike.scala:128)\n\tat scala.collection.AbstractMap.getOrElse(Map.scala:59)\n\tat org.apache.spark.sql.types.StructType.apply(StructType.scala:273)\n\tat org.apache.spark.ml.util.SchemaUtils$.checkNumericType(SchemaUtils.scala:74)\n\tat org.apache.spark.ml.PredictorParams$class.validateAndTransformSchema(Predictor.scala:53)\n\tat org.apache.spark.ml.classification.Classifier.org$apache$spark$ml$classification$ClassifierParams$$super$validateAndTransformSchema(Classifier.scala:58)\n\tat org.apache.spark.ml.classification.ClassifierParams$class.validateAndTransformSchema(Classifier.scala:42)\n\tat org.apache.spark.ml.classification.ProbabilisticClassifier.org$apache$spark$ml$classification$ProbabilisticClassifierParams$$super$validateAndTransformSchema(ProbabilisticClassifier.scala:53)\n\tat org.apache.spark.ml.classification.ProbabilisticClassifierParams$class.validateAndTransformSchema(ProbabilisticClassifier.scala:37)\n\tat org.apache.spark.ml.classification.LogisticRegression.org$apache$spark$ml$classification$LogisticRegressionParams$$super$validateAndTransformSchema(LogisticRegression.scala:279)\n\tat org.apache.spark.ml.classification.LogisticRegressionParams$class.validateAndTransformSchema(LogisticRegression.scala:266)\n\tat org.apache.spark.ml.classification.LogisticRegression.validateAndTransformSchema(LogisticRegression.scala:279)\n\tat org.apache.spark.ml.Predictor.transformSchema(Predictor.scala:144)\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:100)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\n\tat sun.reflect.GeneratedMethodAccessor118.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-835209d7b764>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregParam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"...fitting\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlrModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fitted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlrModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \"\"\"\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: 'Field \"ind_nomina_ult1\" does not exist.\\nAvailable fields: ncodpers, ind_ahor_fin_ult1, ind_aval_fin_ult1, ind_cco_fin_ult1, ind_cder_fin_ult1, ind_cno_fin_ult1, ind_ctju_fin_ult1, ind_ctma_fin_ult1, ind_ctop_fin_ult1, ind_ctpp_fin_ult1, ind_deco_fin_ult1, ind_deme_fin_ult1, ind_dela_fin_ult1, ind_ecue_fin_ult1, ind_fond_fin_ult1, ind_hip_fin_ult1, ind_plan_fin_ult1, ind_pres_fin_ult1, ind_reca_fin_ult1, ind_tjcr_fin_ult1, ind_valo_fin_ult1, ind_viv_fin_ult1, ind_recibo_ult1, imputed_renta, ohe_index_canal_entrada, ohe_index_indresi, ohe_index_indfall, ohe_index_ind_actividad_cliente, ohe_index_tipodom, ohe_index_cod_prov, ohe_index_segmento, ohe_index_sexo, ohe_index_nomprov, ohe_index_pais_residencia, ohe_index_ind_empleado, ohe_index_indext, ohe_index_tiprel_1mes, features'"
     ]
    }
   ],
   "source": [
    "for c in thisList:\n",
    "    print(c)\n",
    "    lr = LogisticRegression(featuresCol=\"features\", labelCol=c, regParam=0.1)\n",
    "    print(\"...fitting\")\n",
    "    lrModel = lr.fit(tra)\n",
    "    print('fitted')\n",
    "    trans = lrModel.transform(test)\n",
    "    print(\"transformed\")\n",
    "    binary_eval=BinaryClassificationEvaluator(labelCol=c)\n",
    "    print(binary_eval.evaluate(trans))\n",
    "    print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data.limit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data1.toPandas() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisList.remove('ind_nomina_ult1')\n",
    "thisList.remove('ind_nom_pens_ult1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_recent = df[['ncodpers']+thisList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_ahor_fin_ult1</th>\n",
       "      <th>ind_aval_fin_ult1</th>\n",
       "      <th>ind_cco_fin_ult1</th>\n",
       "      <th>ind_cder_fin_ult1</th>\n",
       "      <th>ind_cno_fin_ult1</th>\n",
       "      <th>ind_ctju_fin_ult1</th>\n",
       "      <th>ind_ctma_fin_ult1</th>\n",
       "      <th>ind_ctop_fin_ult1</th>\n",
       "      <th>ind_ctpp_fin_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_ecue_fin_ult1</th>\n",
       "      <th>ind_fond_fin_ult1</th>\n",
       "      <th>ind_hip_fin_ult1</th>\n",
       "      <th>ind_plan_fin_ult1</th>\n",
       "      <th>ind_pres_fin_ult1</th>\n",
       "      <th>ind_reca_fin_ult1</th>\n",
       "      <th>ind_tjcr_fin_ult1</th>\n",
       "      <th>ind_valo_fin_ult1</th>\n",
       "      <th>ind_viv_fin_ult1</th>\n",
       "      <th>ind_recibo_ult1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1375586.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ncodpers  ind_ahor_fin_ult1  ind_aval_fin_ult1  ind_cco_fin_ult1  \\\n",
       "0  1375586.0                  0                  0                 1   \n",
       "\n",
       "   ind_cder_fin_ult1  ind_cno_fin_ult1  ind_ctju_fin_ult1  ind_ctma_fin_ult1  \\\n",
       "0                  0                 0                  0                  0   \n",
       "\n",
       "   ind_ctop_fin_ult1  ind_ctpp_fin_ult1       ...         ind_ecue_fin_ult1  \\\n",
       "0                  0                  0       ...                         0   \n",
       "\n",
       "   ind_fond_fin_ult1  ind_hip_fin_ult1  ind_plan_fin_ult1  ind_pres_fin_ult1  \\\n",
       "0                  0                 0                  0                  0   \n",
       "\n",
       "   ind_reca_fin_ult1  ind_tjcr_fin_ult1  ind_valo_fin_ult1  ind_viv_fin_ult1  \\\n",
       "0                  0                  0                  0                 0   \n",
       "\n",
       "   ind_recibo_ult1  \n",
       "0                0  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recent.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if customer already have each product or not. \n",
    "already_active = {}\n",
    "for row in df_recent.values:\n",
    "    row = list(row)\n",
    "    id = row.pop(0)\n",
    "    active = [c[0] for c in zip(tuple(thisList), row) if c[1] > 0]\n",
    "    already_active[id] = active\n",
    "\n",
    "# add 7 products(that user don't have yet), higher probability first -> train_pred   \n",
    "train_preds = {}\n",
    "for id, p in id_preds.items():\n",
    "    # Here be dragons\n",
    "    preds = [i[0] for i in sorted([i for i in zip(tuple(product_col), p) if i[0] not in already_active[id]],\n",
    "                                  key=lambda i:i [1], \n",
    "                                  reverse=True)[:7]]\n",
    "    train_preds[id] = preds\n",
    "    \n",
    "test_preds = []\n",
    "for row in sample.values:\n",
    "    id = row[0]\n",
    "    p = train_preds[id]\n",
    "    test_preds.append(' '.join(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
