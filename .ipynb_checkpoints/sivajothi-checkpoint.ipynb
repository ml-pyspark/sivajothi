{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import  Transformer,Estimator\n",
    "from pyspark.ml.param.shared import HasInputCol,HasOutputCol,HasInputCols,HasOutputCols\n",
    "from pyspark import keyword_only\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import *\n",
    "\n",
    "class LabelEncode(Transformer,HasInputCol,HasOutputCol,HasInputCols,HasOutputCols):\n",
    "    @keyword_only\n",
    "    def __init__(self,outputCols=None):\n",
    "        super(LabelEncode,self).__init__()\n",
    "        kwargs=self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "    @keyword_only\n",
    "    def setParams(self,inputCol=None,outputCols=None):\n",
    "        kwargs=self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    #def xv(self):\n",
    "        #print('xv')\n",
    "    def _transform(self,df):\n",
    "        label_col=self.getOutputCols()\n",
    "        independent_df=df.select(*list(set(df.columns)-set(label_col)))\n",
    "        from pyspark.ml.feature import VectorAssembler,OneHotEncoder,StringIndexer\n",
    "        cc=[cat[0] for cat in independent_df.dtypes if cat[1]=='string']\n",
    "        for column in cc:\n",
    "            sti=StringIndexer(inputCol=column,outputCol='index_'+column)\n",
    "            df=sti.fit(df).transform(df)\n",
    "            df=df.drop(column)\n",
    "        return df\n",
    "    \n",
    "class OHEncode(Transformer,HasInputCol,HasOutputCol,HasOutputCols):\n",
    "    @keyword_only\n",
    "    def __init__(self):\n",
    "        super(OHEncode,self).__init__()\n",
    "        kwargs=self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "    @keyword_only\n",
    "    def setParams(self,inputCol=None,outputCol=None):\n",
    "        kwargs=self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    #def xv(self):\n",
    "        #print('xv')\n",
    "    def _transform(self,df):\n",
    "        from pyspark.ml.feature import VectorAssembler,OneHotEncoder,StringIndexer\n",
    "        #label_column=df.select('TARGET')\n",
    "        #df=df.drop('TARGET')\n",
    "        ohe_columns=[col for col in df.columns if col.startswith('index_')]\n",
    "        ohe_columns=[col for col in ohe_columns if df.select(col).distinct().count()]\n",
    "        for column in ohe_columns:\n",
    "            sti=OneHotEncoder(inputCol=column,outputCol='ohe_'+column)\n",
    "            df=sti.transform(df)\n",
    "            df=df.drop(column)\n",
    "        #print(df.columns)\n",
    "        #df=df.join(label_column)\n",
    "        return df\n",
    "    \n",
    "class VectorChange(Transformer,HasInputCol,HasOutputCol,HasOutputCols):\n",
    "    @keyword_only\n",
    "    def __init__(self,outputCols=None):\n",
    "        super(VectorChange,self).__init__()\n",
    "        kwargs=self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "        \n",
    "    @keyword_only\n",
    "    def setParams(self,inputCol=None,outputCols=None):\n",
    "        kwargs=self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    #def xv(self):\n",
    "        #print('xv')\n",
    "    def _transform(self,df):\n",
    "        \n",
    "        target_col=self.getOutputCols()\n",
    "        from pyspark.ml.feature import VectorAssembler,OneHotEncoder,StringIndexer\n",
    "        #print(list(set(df.columns)-set(target_col)))\n",
    "        assem=VectorAssembler(inputCols=list(set(df.columns)-set(target_col)),outputCol='Feature')\n",
    "        df=assem.transform(df)\n",
    "        #print(df.select('Feature').show())\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('product').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=spark.read.parquet('cleaned_file_v1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data1.limit(700000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[ncodpers: double, ind_empleado: string, pais_residencia: string, sexo: string, age: string, ind_nuevo: string, antiguedad: string, indrel: string, indrel_1mes: string, tiprel_1mes: string, indresi: string, indext: string, canal_entrada: string, indfall: string, tipodom: string, cod_prov: string, nomprov: string, ind_actividad_cliente: string, segmento: string, ind_ahor_fin_ult1: int, ind_aval_fin_ult1: int, ind_cco_fin_ult1: int, ind_cder_fin_ult1: int, ind_cno_fin_ult1: int, ind_ctju_fin_ult1: int, ind_ctma_fin_ult1: int, ind_ctop_fin_ult1: int, ind_ctpp_fin_ult1: int, ind_deco_fin_ult1: int, ind_deme_fin_ult1: int, ind_dela_fin_ult1: int, ind_ecue_fin_ult1: int, ind_fond_fin_ult1: int, ind_hip_fin_ult1: int, ind_plan_fin_ult1: int, ind_pres_fin_ult1: int, ind_reca_fin_ult1: int, ind_tjcr_fin_ult1: int, ind_valo_fin_ult1: int, ind_viv_fin_ult1: int, ind_nomina_ult1: string, ind_nom_pens_ult1: string, ind_recibo_ult1: int, imputed_renta: double]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisList=[col for col in data.columns if col.startswith('ind_') and col.endswith('ult1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(*['age','ind_nuevo','antiguedad','indrel','indrel_1mes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(*['ind_nomina_ult1','ind_nom_pens_ult1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncode(outputCols=thisList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = le.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[ncodpers: double, ind_ahor_fin_ult1: int, ind_aval_fin_ult1: int, ind_cco_fin_ult1: int, ind_cder_fin_ult1: int, ind_cno_fin_ult1: int, ind_ctju_fin_ult1: int, ind_ctma_fin_ult1: int, ind_ctop_fin_ult1: int, ind_ctpp_fin_ult1: int, ind_deco_fin_ult1: int, ind_deme_fin_ult1: int, ind_dela_fin_ult1: int, ind_ecue_fin_ult1: int, ind_fond_fin_ult1: int, ind_hip_fin_ult1: int, ind_plan_fin_ult1: int, ind_pres_fin_ult1: int, ind_reca_fin_ult1: int, ind_tjcr_fin_ult1: int, ind_valo_fin_ult1: int, ind_viv_fin_ult1: int, ind_recibo_ult1: int, imputed_renta: double, index_canal_entrada: double, index_indresi: double, index_indfall: double, index_ind_actividad_cliente: double, index_tipodom: double, index_cod_prov: double, index_segmento: double, index_sexo: double, index_nomprov: double, index_pais_residencia: double, index_ind_empleado: double, index_indext: double, index_tiprel_1mes: double]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OHEncode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=ohe.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[ncodpers: double, ind_ahor_fin_ult1: int, ind_aval_fin_ult1: int, ind_cco_fin_ult1: int, ind_cder_fin_ult1: int, ind_cno_fin_ult1: int, ind_ctju_fin_ult1: int, ind_ctma_fin_ult1: int, ind_ctop_fin_ult1: int, ind_ctpp_fin_ult1: int, ind_deco_fin_ult1: int, ind_deme_fin_ult1: int, ind_dela_fin_ult1: int, ind_ecue_fin_ult1: int, ind_fond_fin_ult1: int, ind_hip_fin_ult1: int, ind_plan_fin_ult1: int, ind_pres_fin_ult1: int, ind_reca_fin_ult1: int, ind_tjcr_fin_ult1: int, ind_valo_fin_ult1: int, ind_viv_fin_ult1: int, ind_recibo_ult1: int, imputed_renta: double, ohe_index_canal_entrada: vector, ohe_index_indresi: vector, ohe_index_indfall: vector, ohe_index_ind_actividad_cliente: vector, ohe_index_tipodom: vector, ohe_index_cod_prov: vector, ohe_index_segmento: vector, ohe_index_sexo: vector, ohe_index_nomprov: vector, ohe_index_pais_residencia: vector, ohe_index_ind_empleado: vector, ohe_index_indext: vector, ohe_index_tiprel_1mes: vector]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler,OneHotEncoder,StringIndexer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler=VectorAssembler(inputCols=list(set(data.columns)-set(thisList)),outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ncodpers: double (nullable = true)\n",
      " |-- ind_ahor_fin_ult1: integer (nullable = true)\n",
      " |-- ind_aval_fin_ult1: integer (nullable = true)\n",
      " |-- ind_cco_fin_ult1: integer (nullable = true)\n",
      " |-- ind_cder_fin_ult1: integer (nullable = true)\n",
      " |-- ind_cno_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ctju_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ctma_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ctop_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ctpp_fin_ult1: integer (nullable = true)\n",
      " |-- ind_deco_fin_ult1: integer (nullable = true)\n",
      " |-- ind_deme_fin_ult1: integer (nullable = true)\n",
      " |-- ind_dela_fin_ult1: integer (nullable = true)\n",
      " |-- ind_ecue_fin_ult1: integer (nullable = true)\n",
      " |-- ind_fond_fin_ult1: integer (nullable = true)\n",
      " |-- ind_hip_fin_ult1: integer (nullable = true)\n",
      " |-- ind_plan_fin_ult1: integer (nullable = true)\n",
      " |-- ind_pres_fin_ult1: integer (nullable = true)\n",
      " |-- ind_reca_fin_ult1: integer (nullable = true)\n",
      " |-- ind_tjcr_fin_ult1: integer (nullable = true)\n",
      " |-- ind_valo_fin_ult1: integer (nullable = true)\n",
      " |-- ind_viv_fin_ult1: integer (nullable = true)\n",
      " |-- ind_recibo_ult1: integer (nullable = true)\n",
      " |-- imputed_renta: double (nullable = true)\n",
      " |-- ohe_index_canal_entrada: vector (nullable = true)\n",
      " |-- ohe_index_indresi: vector (nullable = true)\n",
      " |-- ohe_index_indfall: vector (nullable = true)\n",
      " |-- ohe_index_ind_actividad_cliente: vector (nullable = true)\n",
      " |-- ohe_index_tipodom: vector (nullable = true)\n",
      " |-- ohe_index_cod_prov: vector (nullable = true)\n",
      " |-- ohe_index_segmento: vector (nullable = true)\n",
      " |-- ohe_index_sexo: vector (nullable = true)\n",
      " |-- ohe_index_nomprov: vector (nullable = true)\n",
      " |-- ohe_index_pais_residencia: vector (nullable = true)\n",
      " |-- ohe_index_ind_empleado: vector (nullable = true)\n",
      " |-- ohe_index_indext: vector (nullable = true)\n",
      " |-- ohe_index_tiprel_1mes: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "model_preds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra=train.limit(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...fitting\n",
      "fitted\n"
     ]
    }
   ],
   "source": [
    "for c in thisList:\n",
    "    print(c)\n",
    "    lr = LogisticRegression(featuresCol=\"features\", labelCol=c, regParam=0.1)\n",
    "    print(\"...fitting\")\n",
    "    lrModel = lr.fit(tra)\n",
    "    print('fitted')\n",
    "    trans = lrModel.transform(test)\n",
    "    print(\"transformed\")\n",
    "    binary_eval=BinaryClassificationEvaluator(labelCol=c)\n",
    "    print(binary_eval.evaluate(trans))\n",
    "    print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed\n",
      "DataFrame[ncodpers: double, ind_ahor_fin_ult1: int, ind_aval_fin_ult1: int, ind_cco_fin_ult1: int, ind_cder_fin_ult1: int, ind_cno_fin_ult1: int, ind_ctju_fin_ult1: int, ind_ctma_fin_ult1: int, ind_ctop_fin_ult1: int, ind_ctpp_fin_ult1: int, ind_deco_fin_ult1: int, ind_deme_fin_ult1: int, ind_dela_fin_ult1: int, ind_ecue_fin_ult1: int, ind_fond_fin_ult1: int, ind_hip_fin_ult1: int, ind_plan_fin_ult1: int, ind_pres_fin_ult1: int, ind_reca_fin_ult1: int, ind_tjcr_fin_ult1: int, ind_valo_fin_ult1: int, ind_viv_fin_ult1: int, ind_recibo_ult1: int, imputed_renta: double, ohe_index_canal_entrada: vector, ohe_index_indresi: vector, ohe_index_indfall: vector, ohe_index_ind_actividad_cliente: vector, ohe_index_tipodom: vector, ohe_index_cod_prov: vector, ohe_index_segmento: vector, ohe_index_sexo: vector, ohe_index_nomprov: vector, ohe_index_pais_residencia: vector, ohe_index_ind_empleado: vector, ohe_index_indext: vector, ohe_index_tiprel_1mes: vector, features: vector, rawPrediction: vector, probability: vector, prediction: double]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8264857354164908\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(\"...predicting\")\n",
    "    res = lrModel.transform(test)\n",
    "    print(\"...appending result\")\n",
    "    test_res = test_res.join(res.select('id', 'probability'), on=\"id\")\n",
    "    print(\"...extracting probability\")\n",
    "    test_res = test_res.withColumn(col, extract_prob('probability')).drop(\"probability\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(*thisList, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c='ind_valo_fin_ult1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c)\n",
    "# train model here with june 2015 data\n",
    "y_train = train[c]\n",
    "print(\"1\")\n",
    "x_train = train.drop(*thisList)\n",
    "print(\"2\")\n",
    "print(x_train.printSchema())\n",
    "print(\"3\")\n",
    "clf = LogisticRegression()\n",
    "#pip=Pipeline(stages=clf)\n",
    "#data=pip.fit(data).transform(data)\n",
    "clf.fit(data,y_train)\n",
    "\n",
    "# pridict model with the most recent data\n",
    "#y_train2 = df_train[c]\n",
    "#x_train2 = df_test.drop(['ncodpers',\"fecha_dato\"], 1)\n",
    "p_train = clf.predict_proba(x_train)[:,1]\n",
    "#p_train2 = clf.predict_proba(x_train)[:,1]\n",
    "\n",
    "models[c] = clf\n",
    "model_preds[c] = p_train\n",
    "\n",
    "print(roc_auc_score(y_train, p_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
